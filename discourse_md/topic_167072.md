# Topic: Sudo permission needed to create data folder in root?

### Post #1 by **Vikram Suriyanarayanan** (ds-students)
*February 14, 2025, 03:57 UTC*
[@Jivraj](https://discourse.onlinedegree.iitm.ac.in/u/jivraj) [@carlton](https://discourse.onlinedegree.iitm.ac.in/u/carlton) sir please help

When I am downloading the data folder after processing datagen.py , it is trying to download in root folder and it is facing permission error . how can we overcome this ?  
needs sudo permission all the time…  



> **Image Content:** *Here's an analysis of the key information from the screenshot, presented as if for a data science course forum, with exact transcriptions:

**Key Information from the Screenshot:**

The screenshot displays a user's terminal session, likely within a Linux environment (most probably Windows Subsystem for Linux given the `/mnt/c` path), working on a project related to an "IIT Madras TDS Project."

1.  **User Context:** The user is `vikramjnc...@ANJANEYA` and is currently in the directory `/mnt/c/IIT_Madras/TDS_Project_1`. This suggests they are working on a specific project as part of an academic course, likely "Data Science" (TDS could stand for "The Data Science" or a related abbreviation). The `/mnt/c` path is characteristic of a Windows Subsystem for Linux (WSL) setup, where the Linux environment can access Windows drives.

2.  **Commands Executed:**
    *   **First Command (Partially Visible):** A highly destructive command, `sudo rm -rf /data`, was initiated. This command attempts to recursively and forcefully remove the entire `/data` directory from the root of the file system. In a data science context, the `/data` directory is often used to store large datasets. Executing such a command without full understanding can lead to significant data loss. Its outcome is not shown, but it precedes the `ls` command.
    *   **Second Command:** `ls /` was executed. This command lists the contents of the root directory (`/`) of the Linux file system.

3.  **Output:** The `ls /` command successfully executed and listed the standard top-level directories found in a Linux file system.
    *   Notable directories include `bin`, `boot`, `dev`, `etc`, `home`, `lib`, `mnt`, `opt`, `proc`, `root`, `sbin`, `srv`, `sys`, `tmp`, `usr`, `var`.
    *   `init` and `tmp` directories are highlighted in green, which often indicates they are directories with special permissions (e.g., world-writable or executable) or links, depending on the terminal's color scheme.
    *   The presence of `lib.usr-is-merged` and `sbin.usr-is-merged` suggests a modern Linux distribution (like Ubuntu or Debian-based systems) that has merged `/bin`, `/sbin`, `/lib` into `/usr/bin`, `/usr/sbin`, `/usr/lib` respectively, with symbolic links back to maintain compatibility.
    *   `snap` indicates the presence of Snap packaging system, common in Ubuntu.

4.  **No Errors:** The `ls /` command completed without any visible error messages, returning the user to the prompt.

**Transcript of Code, Commands, or Error Messages:**

```
vikramjnc...@ANJANEYA:/mnt/c/IIT_Madras/TDS_Project_1$ sudo rm -rf /data
vikramjnc...@ANJANEYA:/mnt/c/IIT_Madras/TDS_Project_1$ ls /
bin  boot  etc  init  lib.usr-is-merged  lost+found  mnt  proc  run  sbin.usr-is-merged  srv  tmp  var
bin.usr-is-merged  dev  home  lib  lib64  media  opt  root  sbin  snap  sys  usr
vikramjnc...@ANJANEYA:/mnt/c/IIT_Madras/TDS_Project_1$
```*



---

### Post #2 by **Carlton D'Silva** (Regular, ds-students)
*February 14, 2025, 04:53 UTC*
Hi Vikram,

This is because (if you watched the session, or examined the code, you would have realised that) datagen.py was designed to run inside your docker container. And datagen.py (or a similar named file which we will not tell you ahead of time and will be provided as the query parameter in task A1) will normally be called by evaluate.py  
Inside the docker container, permission for the data folder is set by the Dockerfile  
which then allows your application to access the root folder inside your docker image and create the /data folder.

So the workflow is like this (for your internal testing only… please follow the Project page for deliverables and evaluation to submit project successfully):

1. You create your application server that serves 2 endpoints on localhost:8000
2. You create a docker image that runs this application server.
3. You run the docker image using podman as described in the project page.
4. For mimicking the testing conditions. You need two files:  
   evaluate.py and datagen.py to be in the same folder where you are running these two scripts.
5. Run evalute.py using uv.

If your docker image is correctly configured and your application is correctly configured, then all the tasks run by evaluate.py will correctly tell you if the application is producing the right result for each task.

Hope that gives clarity.

Kind regards

---
